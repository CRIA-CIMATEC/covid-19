{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "np.seterr(all='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alterar='20200908'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bd = pd.read_csv('data/dados_gerais_'+alterar+'.csv',sep=\",\") #A variável de interesse tem que estar nomeada como \"Confirmed\"\n",
    "bd1 = pd.read_csv('data/dados_nacionais_'+alterar+'.csv',sep=\",\") #A variável de interesse tem que estar nomeada como \"Confirmed\"\n",
    "bd2 = pd.read_csv('data/dados_mundiais_'+alterar+'.csv',sep=\",\") #A variável de interesse tem que estar nomeada como \"Confirmed\"\n",
    "\n",
    "bd[\"preinflex\"]=0\n",
    "bd[\"peak\"]=0\n",
    "bd[\"postinflex\"]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando modelo pontencial exponencial para prever pontos de inflexão, pico e dia de término da pandemia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "country=bd[\"Country/Region\"].unique()\n",
    "for s in country: \n",
    "    _f1 = bd[\"Country/Region\"] == s\n",
    "    data=bd[_f1]\n",
    "    data=data.loc[:,\"Confirmed\"].reset_index(drop= True)\n",
    "    data=data.values \n",
    "\n",
    "    n = len(data)\n",
    "    g = data.cumsum()\n",
    "    M = data.max()\n",
    "    t = np.where(data == data.max())[0]#[0]+1\n",
    "    tM=np.where(data == data.max())[0][len(t)-1]+1\n",
    "    tM1 = round(tM-0.15*n)\n",
    "    tM2 = round(tM+0.15*n)\n",
    "    _sum = data.sum()\n",
    "\n",
    "    f = np.empty(n)\n",
    "    mloss = 1e90\n",
    "    itr = 0\n",
    "\n",
    "    for c in np.arange(-0.05, -1.51, -0.05):\n",
    "        start, end = -c*tM1, (-c*tM2)+0.1\n",
    "        for b in np.arange(start, end, 0.1):\n",
    "            for i in range(n):\n",
    "                f[i] = np.power(i+1, b) * np.exp(c*(i+1))\n",
    "            a = _sum / f.sum()\n",
    "            F = a * f\n",
    "            loss = np.linalg.norm(data-F)\n",
    "            if loss < mloss:\n",
    "                besta = a\n",
    "                bestb = b\n",
    "                bestc = c\n",
    "                bestarea = np.around(F.sum(), 2)\n",
    "                mloss = loss;\n",
    "                itr += 1\n",
    "                F2plt = F\n",
    "\n",
    "    bd.loc[_f1,\"preinflex\"]+=round(-(bestb-math.sqrt(math.fabs(bestb)))/bestc ) \n",
    "    bd.loc[_f1,\"peak\"] +=round(-bestb/bestc)\n",
    "#     bd.loc[_f1,\"cases_day\"] += round(besta*(np.power((-bestb/bestc), bestb))*np.exp(bestc*(-bestb/bestc)))\n",
    "    bd.loc[_f1,\"postinflex\"] += round(-(bestb+math.sqrt(math.fabs(bestb)))/bestc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo estágio atual da pandemia por país"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=bd\n",
    "country=df[\"Country/Region\"].unique()\n",
    "for s in country: \n",
    "    _f1 = df[\"Country/Region\"] == s\n",
    "    data=df[_f1]\n",
    "    data=len(data.loc[next(x for x in data[data[\"Confirmed\"]>0].index):,\"Confirmed\"].reset_index(drop= True))\n",
    "    if data <= df.loc[_f1,\"preinflex\"].values[0]:\n",
    "        df.loc[_f1,\"estagio\"]=1\n",
    "    elif data<df.loc[_f1,\"peak\"].values[0]:\n",
    "        df.loc[_f1,\"estagio\"]=2\n",
    "    elif data==df.loc[_f1,\"postinflex\"].values[0]:\n",
    "        df.loc[_f1,\"estagio\"]=3\n",
    "    elif data<=df.loc[_f1,\"postinflex\"].values[0]:\n",
    "        df.loc[_f1,\"estagio\"]=4\n",
    "    else: df.loc[_f1,\"estagio\"]=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados para modelagem de notas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notas=df.dropna(subset=[\"populacao\",\"day_of_week\"]).reset_index(drop=True)\n",
    "df_notas=df_notas.drop(columns=[\"estagio\",\"preinflex\",\"postinflex\",\"peak\"])\n",
    "df_notas.to_csv('./datasets/dados_notas_'+alterar+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_casos=df.drop(columns=[\"day_of_week\", \"Qtde Autorizados\", \"Valor Autorizados\", \"populacao\",\"Qtde Autorizados_2019_mean\",\"Valor Autorizados_2019_mean\",\"preinflex\",\"postinflex\",\"peak\"])\n",
    "df_casos1=df_casos.drop(columns=[\"estagio\"])\n",
    "df_casos1=df_casos1.dropna()\n",
    "df_casos1.to_csv('./datasets/complete_mundial_estadual_model_'+alterar+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do total de 200 países:\n",
      "1 (0%) estão no estágio 1 da pandemia\n",
      "21 (10%) estão no estágio 2 da pandemia\n",
      "2 (1%) estão no estágio 3 da pandemia\n",
      "40 (20%) estão no estágio 4 da pandemia\n",
      "136 (68%) estão no estágio 5 da pandemia\n"
     ]
    }
   ],
   "source": [
    "df_all=df.loc[:,[\"Country/Region\",\"estagio\"]].drop_duplicates()\n",
    "\n",
    "estagio2= df_all[\"Country/Region\"][df_all[\"estagio\"]==2]\n",
    "estagio1= df_all[\"Country/Region\"][df_all[\"estagio\"]==1]\n",
    "estagio4= df_all[\"Country/Region\"][df_all[\"estagio\"]==4]\n",
    "estagio5= df_all[\"Country/Region\"][df_all[\"estagio\"]==5]\n",
    "estagio3= df_all[\"Country/Region\"][df_all[\"estagio\"]==3]\n",
    "\n",
    "n=len(df_all)\n",
    "n2=len(estagio2)\n",
    "n1=len(estagio1)\n",
    "n4=len(estagio4)\n",
    "n5=len(estagio5)\n",
    "n3=len(estagio3)\n",
    "p2=round(n2*100/n)\n",
    "p3=round(n3*100/n)\n",
    "p1=round(n1*100/n)\n",
    "p4=round(n4*100/n)\n",
    "p5=round(n5*100/n)\n",
    "\n",
    "print(f'Do total de {n} países:')\n",
    "print(f'{n1} ({p1}%) estão no estágio 1 da pandemia')\n",
    "print(f'{n2} ({p2}%) estão no estágio 2 da pandemia')\n",
    "print(f'{n3} ({p3}%) estão no estágio 3 da pandemia')\n",
    "print(f'{n4} ({p4}%) estão no estágio 4 da pandemia')\n",
    "print(f'{n5} ({p5}%) estão no estágio 5 da pandemia')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados para modelagem de casos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/miniconda3/envs/covid-web/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/lucas/miniconda3/envs/covid-web/lib/python3.7/site-packages/ipykernel_launcher.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/lucas/miniconda3/envs/covid-web/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "if n1<2:\n",
    "    df_casos=df_casos[df_casos[\"estagio\"]!=1]\n",
    "if n2<2:\n",
    "    df_casos=df_casos[df_casos[\"estagio\"]!=2]\n",
    "if n3<2:\n",
    "    df_casos=df_casos[df_casos[\"estagio\"]!=3]\n",
    "if n4<2:\n",
    "    df_casos=df_casos[df_casos[\"estagio\"]!=4]\n",
    "if n5<2:\n",
    "    df_casos=df_casos[df_casos[\"estagio\"]!=5]\n",
    "\n",
    "dados_sinteticos_filtrado=df_casos.copy()\n",
    "# dados_sinteticos_filtrado=df_casos[df_casos[\"estagio\"]!=3]\n",
    "\n",
    "intervalo = (dados_sinteticos_filtrado['Country/Region'] == 'Spain') | (dados_sinteticos_filtrado['Country/Region'] == 'Brazil')|(dados_sinteticos_filtrado['Country/Region'] == 'United States')| (dados_sinteticos_filtrado['Country/Region'] == 'China')\n",
    "intervalo1= (dados_sinteticos_filtrado['Country/Region'] == 'BA') | (dados_sinteticos_filtrado['Country/Region'] == 'RJ')\n",
    "intervalo2=(dados_sinteticos_filtrado['Country/Region'] == 'ES')| (dados_sinteticos_filtrado['Country/Region'] == 'AL')\n",
    "intervalo3=(dados_sinteticos_filtrado['Country/Region'] == 'AC')| (dados_sinteticos_filtrado['Country/Region'] == 'PB')| (dados_sinteticos_filtrado['Country/Region'] == 'PI')| (dados_sinteticos_filtrado['Country/Region'] == 'RN')|(dados_sinteticos_filtrado['Country/Region'] == 'RO')| (dados_sinteticos_filtrado['Country/Region'] == 'RR')| (dados_sinteticos_filtrado['Country/Region'] == 'RS')| (dados_sinteticos_filtrado['Country/Region'] == 'SE')\n",
    "\n",
    "dados_sinteticos_filtrado.drop(dados_sinteticos_filtrado[intervalo].index, inplace=True)\n",
    "dados_sinteticos_filtrado.drop(dados_sinteticos_filtrado[intervalo1].index, inplace=True)\n",
    "dados_sinteticos_filtrado.drop(dados_sinteticos_filtrado[intervalo2].index, inplace=True)\n",
    "dados_sinteticos_filtrado.drop(dados_sinteticos_filtrado[intervalo3].index, inplace=True)\n",
    "dados_sinteticos_filtrado = dados_sinteticos_filtrado.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "banco=dados_sinteticos_filtrado[[\"Country/Region\",\"estagio\"]].drop_duplicates().reset_index(drop=True)\n",
    "regions_info = banco.groupby('Country/Region').max()\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.30, random_state=0)\n",
    "\n",
    "regions = list(regions_info.index)\n",
    "classes = list(regions_info['estagio'])\n",
    "\n",
    "for train_index, test_index in sss.split(regions, classes):\n",
    "#     print(len(test_index))\n",
    "    regions_train, regions_test = regions_info.iloc[train_index,:], regions_info.iloc[test_index,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_test=dados_sinteticos_filtrado[dados_sinteticos_filtrado[\"Country/Region\"].isin(list(regions_test.index))]\n",
    "\n",
    "regions_train=dados_sinteticos_filtrado[dados_sinteticos_filtrado[\"Country/Region\"].isin(list(regions_train.index))]\n",
    "\n",
    "regions_test = pd.concat([regions_test,  df_casos[df_casos['Country/Region'] == 'Brazil']],axis=0)\n",
    "regions_test = pd.concat([regions_test,  df_casos[df_casos['Country/Region'] == 'Spain']],axis=0)\n",
    "regions_test = pd.concat([regions_test,  df_casos[df_casos['Country/Region'] == 'BA']],axis=0)\n",
    "regions_test = pd.concat([regions_test,  df_casos[df_casos['Country/Region'] == 'RJ']],axis=0)\n",
    "regions_test=regions_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do total de 128 países:\n",
      "0 (0%) estão no estágio 1 da pandemia\n",
      "14 (11%) estão no estágio 2 da pandemia\n",
      "1 (1%) estão no estágio 3 da pandemia\n",
      "26 (20%) estão no estágio 4 da pandemia\n",
      "87 (68%) estão no estágio 5 da pandemia\n"
     ]
    }
   ],
   "source": [
    "df_all=regions_train.loc[:,[\"Country/Region\",\"estagio\"]].drop_duplicates()\n",
    "\n",
    "estagio2= df_all[\"Country/Region\"][df_all[\"estagio\"]==2]\n",
    "estagio1= df_all[\"Country/Region\"][df_all[\"estagio\"]==1]\n",
    "estagio4= df_all[\"Country/Region\"][df_all[\"estagio\"]==4]\n",
    "estagio5= df_all[\"Country/Region\"][df_all[\"estagio\"]==5]\n",
    "estagio3= df_all[\"Country/Region\"][df_all[\"estagio\"]==3]\n",
    "\n",
    "n=len(df_all)\n",
    "n2=len(estagio2)\n",
    "n1=len(estagio1)\n",
    "n4=len(estagio4)\n",
    "n5=len(estagio5)\n",
    "n3=len(estagio3)\n",
    "p2=round(n2*100/n)\n",
    "p3=round(n3*100/n)\n",
    "p1=round(n1*100/n)\n",
    "p4=round(n4*100/n)\n",
    "p5=round(n5*100/n)\n",
    "\n",
    "print(f'Do total de {n} países:')\n",
    "print(f'{n1} ({p1}%) estão no estágio 1 da pandemia')\n",
    "print(f'{n2} ({p2}%) estão no estágio 2 da pandemia')\n",
    "print(f'{n3} ({p3}%) estão no estágio 3 da pandemia')\n",
    "print(f'{n4} ({p4}%) estão no estágio 4 da pandemia')\n",
    "print(f'{n5} ({p5}%) estão no estágio 5 da pandemia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n1<2:\n",
    "    regions_train=regions_train[regions_train[\"estagio\"]!=1]\n",
    "if n2<2:\n",
    "    regions_train=regions_train[regions_train[\"estagio\"]!=2]\n",
    "if n3<2:\n",
    "    regions_train=regions_train[regions_train[\"estagio\"]!=3]\n",
    "if n4<2:\n",
    "    regions_train=regions_train[regions_train[\"estagio\"]!=4]\n",
    "if n5<2:\n",
    "    regions_train=regions_train[regions_train[\"estagio\"]!=5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "banco=regions_train[[\"Country/Region\",\"estagio\"]].drop_duplicates().reset_index(drop=True)\n",
    "regions_info = banco.groupby('Country/Region').max()\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.50, train_size=0.50, random_state=0)\n",
    "\n",
    "regions = list(regions_info.index)\n",
    "classes = list(regions_info['estagio'])\n",
    "\n",
    "for train_index, val_index in sss.split(regions, classes):\n",
    "#     print(len(test_index))\n",
    "    regions_train, regions_val = regions_info.iloc[train_index,:], regions_info.iloc[val_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_train=dados_sinteticos_filtrado[dados_sinteticos_filtrado[\"Country/Region\"].isin(list(regions_train.index))]\n",
    "regions_train = pd.concat([regions_train,  df_casos[df_casos['Country/Region'] == 'China']],axis=0)\n",
    "regions_train = pd.concat([regions_train,  df_casos[df_casos['Country/Region'] == 'United States']],axis=0)\n",
    "regions_train = pd.concat([regions_train,  df_casos[df_casos['Country/Region'] == 'AC']],axis=0)\n",
    "regions_train = pd.concat([regions_train,  df_casos[df_casos['Country/Region'] == 'PB']],axis=0)\n",
    "regions_train = pd.concat([regions_train,  df_casos[df_casos['Country/Region'] == 'PI']],axis=0)\n",
    "regions_train = pd.concat([regions_train,  df_casos[df_casos['Country/Region'] == 'RN']],axis=0)\n",
    "regions_train = pd.concat([regions_train,  df_casos[df_casos['Country/Region'] == 'RO']],axis=0)\n",
    "regions_train = pd.concat([regions_train,  df_casos[df_casos['Country/Region'] == 'RS']],axis=0)\n",
    "regions_train = pd.concat([regions_train,  df_casos[df_casos['Country/Region'] == 'RR']],axis=0)\n",
    "regions_train = pd.concat([regions_train,  df_casos[df_casos['Country/Region'] == 'PE']],axis=0)\n",
    "regions_train=regions_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_val=dados_sinteticos_filtrado[dados_sinteticos_filtrado[\"Country/Region\"].isin(list(regions_val.index))]\n",
    "regions_val = pd.concat([regions_val,  df_casos[df_casos['Country/Region'] == 'AL']],axis=0)\n",
    "regions_val = pd.concat([regions_val,  df_casos[df_casos['Country/Region'] == 'ES']],axis=0)\n",
    "regions_val=regions_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do total de 66 países:\n",
      "0 (0%) estão no estágio 1 da pandemia\n",
      "7 (11%) estão no estágio 2 da pandemia\n",
      "0 (0%) estão no estágio 3 da pandemia\n",
      "13 (20%) estão no estágio 4 da pandemia\n",
      "46 (70%) estão no estágio 5 da pandemia\n"
     ]
    }
   ],
   "source": [
    "df_all=regions_val.loc[:,[\"Country/Region\",\"estagio\"]].drop_duplicates()\n",
    "\n",
    "estagio2= df_all[\"Country/Region\"][df_all[\"estagio\"]==2]\n",
    "estagio1= df_all[\"Country/Region\"][df_all[\"estagio\"]==1]\n",
    "estagio4= df_all[\"Country/Region\"][df_all[\"estagio\"]==4]\n",
    "estagio5= df_all[\"Country/Region\"][df_all[\"estagio\"]==5]\n",
    "estagio3= df_all[\"Country/Region\"][df_all[\"estagio\"]==3]\n",
    "\n",
    "n=len(df_all)\n",
    "n2=len(estagio2)\n",
    "n1=len(estagio1)\n",
    "n4=len(estagio4)\n",
    "n5=len(estagio5)\n",
    "n3=len(estagio3)\n",
    "p2=round(n2*100/n)\n",
    "p3=round(n3*100/n)\n",
    "p1=round(n1*100/n)\n",
    "p4=round(n4*100/n)\n",
    "p5=round(n5*100/n)\n",
    "\n",
    "print(f'Do total de {n} países:')\n",
    "print(f'{n1} ({p1}%) estão no estágio 1 da pandemia')\n",
    "print(f'{n2} ({p2}%) estão no estágio 2 da pandemia')\n",
    "print(f'{n3} ({p3}%) estão no estágio 3 da pandemia')\n",
    "print(f'{n4} ({p4}%) estão no estágio 4 da pandemia')\n",
    "print(f'{n5} ({p5}%) estão no estágio 5 da pandemia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando treinamento,validação e teste-casos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_val=regions_val.dropna()\n",
    "regions_test=regions_test.dropna()\n",
    "regions_train=regions_train.dropna()\n",
    "\n",
    "regions_train.to_csv('./datasets/train_mundial_estadual_model_'+alterar+'.csv',index=False)\n",
    "regions_test.to_csv('./datasets/test_mundial_estadual_model_'+alterar+'.csv',index=False)\n",
    "regions_val.to_csv('./datasets/val_mundial_estadual_model_'+alterar+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados para modelagem pico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pico=df.drop(columns=[\"day_of_week\", \"Qtde Autorizados\", \"Valor Autorizados\", \"populacao\",\"Qtde Autorizados_2019_mean\",\"Valor Autorizados_2019_mean\"])\n",
    "df_pico1=df_pico.drop(columns=[\"estagio\"])\n",
    "df_pico1=df_pico1.dropna()\n",
    "df_pico1.to_csv('./datasets/complete_mundial_estadual_model_peak_'+alterar+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_sinteticos_filtrado=df_pico.copy()\n",
    "intervalo = ((dados_sinteticos_filtrado['estagio'] == 1) | (dados_sinteticos_filtrado['estagio'] == 2) | (dados_sinteticos_filtrado['estagio'] == 3))\n",
    "dados_sinteticos_filtrado.drop(dados_sinteticos_filtrado[intervalo].index, inplace=True)\n",
    "dados_sinteticos_filtrado = dados_sinteticos_filtrado.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervalo1 = ((dados_sinteticos_filtrado['Country/Region'] == \"Spain\")|(dados_sinteticos_filtrado['Country/Region'] == \"Italy\"))\n",
    "dados_sinteticos_filtrado.drop(dados_sinteticos_filtrado[intervalo1].index, inplace=True)\n",
    "dados_sinteticos_filtrado = dados_sinteticos_filtrado.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "banco=dados_sinteticos_filtrado[[\"Country/Region\",\"estagio\"]].drop_duplicates().reset_index(drop=True)\n",
    "regions_info = banco.groupby('Country/Region').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.10, train_size=0.90, random_state=1)\n",
    "\n",
    "regions = list(regions_info.index)\n",
    "classes = list(regions_info['estagio'])\n",
    "\n",
    "for train_index, test_index in sss.split(regions, classes):\n",
    "#     print(len(test_index))\n",
    "    regions_train, regions_test = regions_info.iloc[train_index,:], regions_info.iloc[test_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_test=dados_sinteticos_filtrado[dados_sinteticos_filtrado[\"Country/Region\"].isin(list(regions_test.index))]\n",
    "\n",
    "regions_train=dados_sinteticos_filtrado[dados_sinteticos_filtrado[\"Country/Region\"].isin(list(regions_train.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_test = pd.concat([regions_test,  df_pico[df_pico['Country/Region'] == 'Italy']],axis=0)\n",
    "regions_test = pd.concat([regions_test,  df_pico[df_pico['Country/Region'] == 'Spain']],axis=0)\n",
    "# regions_test=pd.concat([regions_test,dadosBR_test],axis=0, sort=True)\n",
    "regions_test=regions_test.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "banco=regions_train[[\"Country/Region\",\"estagio\"]].drop_duplicates().reset_index(drop=True)\n",
    "regions_info = banco.groupby('Country/Region').max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.50, train_size=0.50, random_state=0)\n",
    "\n",
    "regions = list(regions_info.index)\n",
    "classes = list(regions_info['estagio'])\n",
    "\n",
    "for train_index, val_index in sss.split(regions, classes):\n",
    "#     print(len(test_index))\n",
    "    regions_train, regions_val = regions_info.iloc[train_index,:], regions_info.iloc[val_index,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_val=dados_sinteticos_filtrado[dados_sinteticos_filtrado[\"Country/Region\"].isin(list(regions_val.index))]\n",
    "\n",
    "regions_train=dados_sinteticos_filtrado[dados_sinteticos_filtrado[\"Country/Region\"].isin(list(regions_train.index))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_val=regions_val.dropna()\n",
    "regions_test=regions_test.dropna()\n",
    "regions_train=regions_train.dropna()\n",
    "\n",
    "regions_train.to_csv(\"./datasets/train_mundial_estadual_model_peak_\"+alterar+\".csv\",index=False)\n",
    "regions_test.to_csv(\"./datasets/test_mundial_estadual_model_peak_\"+alterar+\".csv\",index=False)\n",
    "regions_val.to_csv(\"./datasets/val_mundial_estadual_model_peak_\"+alterar+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
